{:title "Notes on Optimizing Clojure Code: Measurements"
 :layout :post
 :tags ["clojure"]}

Over the month of December, I've spent a lot of time trying to optimize my
solutions to [Advent of Code][aoc], with reasonable success. I thought I'd
collect my learnings in a set of notes for my future self, and share that with
you. Not all of this is Clojure-specific, but the details mostly are.

### Why optimize code?

Frankly, because _it's fun_.

For the sake of argument, let's assume you need to make your code faster
because it is too slow for the context it's being run in. In the case of Advent
of Code, I'm putting on myself the arbitrary constraint of running each day
under a second. That's pretty easy for the first few days, but gets a bit
harder on the later challenges.

In a more realistic context, maybe you have a website that's not as snappy as
you'd want, or you have to run a batch job every hour and it's taking 63
minutes and growing, or you have to run a script on your laptop and wait for it
to finish before you can do something else.

Whatever the details, context matters in two very specific ways:

1. It can tell us when to stop. Once your code is "fast enough", you don't need
   to optimize it further. Optimizing code often (though not always) comes at a
   cost to maintainability, so it should be done with some amount of reluctance on
   long-lived production code.
2. It tells us _how much_ code we need to care about. Specifically, all of the
   code involved in the realistic use-case that is currently "too slow", but
   not the rest of the code. This is really important if you want to be efficient
   in your optimization efforts, especially on large code bases.

### The process of optimizing code

In most cases, when a software application is too slow, the vast majority of
its time is spent in a very small fraction of the code, which we therefore call
"the bottleneck". Optimizing is an iterative process that goes a bit like this:

1. Find a section of code that is too slow for some inputs. This is usually
   done with the help of some _logging_ techniques.
2. Create a _benchmark_ that exercises that section of code with a
   representative set of inputs. In simple cases this is just a new entrypoint
   in your application; in more complex cases it may be a separate project
   containing a copy of just the code you want to focus on optimizing.
3. Try to gain insights into what, specifically, is slow, where time is spent,
   and how things could be made faster. This is often helped by _profiling_ the
   code.
4. Iterate on the benchmark until it is fast enough.
5. Integrate your optimizations in the main code and try it on real use-cases
   again. If it's now fast enough, you're done. If you identify new cases for
   which it's too slow, keep going.

In this post, I'll give a brief overview of how I approach performance logging,
benchmarking and profiling Clojure code.

### General notes

The JVM is a complex tool with pretty advanced JIT capabilities. While that's
great for performance overall, it does make optimization a little bit harder,
as what goes fast can boil down to what the JIT is able to optimize, and that's
not always easy to predict.

It's also a garbage-collected platform, and in long-lived real-world use-cases
garbage collection can take up a significant proportion of run time. But the
JVM has many different GC algorithms to choose from, each with a plethora of
fine-tuning options. How friendly your code is to the particular GC you're
running with can have a pretty big impact on performance.

All of that is to say that the environment you run your code in matters;
specifically, the configuration of the underlying JVM matters. I highly
recommend running all of your measurements under realistic scenarios; in the
particular case of Clojure, this means I recommend against trying to take
measurements from a REPL and instead running your code through your deployment
pipeline instead. That usually means creating an AOT compiled JAR and running
it with the same JVM version and same set of flags as you use in production.
I'll reiterate on that point a couple time below.

### Performance logging

At its most basic, performance logging can just be timestamping your logs. In
many cases that will be enough to give you a rough idea of which parts of your
code are slow, and that's really all we're after here.

The less linear your code is, the less effective that naive approach will be.
My tool of choice for performance logging is [tufte], which was extracted from
the [timbre] logging library. Compared to just adding timestamps to your
existing logs, its main advantage is that it will compute summarized times for
you.

Let's see how it works on a concrete example. A few weeks ago I was [trying to
compute prime numbers][primes], and, at some point, I ended up with this piece
of code:

```clojure
(defn bitset-sieve
  [^long bound]
  (let [candidates (java.util.BitSet. bound)]
    (.set candidates 2 bound)
    (loop [idx 2]
      (when (< idx bound)
        (when-let [next-candidate (.get candidates idx)]
          (loop [update-idx (* idx idx)]
            (when (< update-idx bound)
              (.clear candidates update-idx)
              (recur (+ idx update-idx)))))
        (recur (inc idx))))
    (take-while pos? (iterate #(.nextSetBit candidates (inc %)) 2))))
```

At its most basic, the [tufte] library can be understood in terms of two
constructs:

- The `profiled` macro takes a single expression and returns a vector where the
  first element is the result of the given expression, and the second element
  is a summarized result of all the measurements taken.
- The `p` macro takes a keyword and an expression, and returns the result of
  that expression. It also, through side-effects, registers the time it took to
  compute that results under the given keyword.

Looking back at the prime computation above, we could get some insight about
how much time is spent in each part by annotating it with calls to the `p`
macro:

```clojure
(ns t.core
  (:require [taoensso.tufte :as tufte :refer (p profiled)]
            [clojure.pprint :refer [pprint]])
  (:gen-class))

(defn bitset-sieve
  [^long bound]
  (let [candidates (java.util.BitSet. bound)]
    (p :init (.set candidates 2 bound))
    (p :main-loop
       (loop [idx 2]
         (when (< idx bound)
           (when-let [next-candidate (.get candidates idx)]
             (loop [update-idx (* idx idx)]
               (when (< update-idx bound)
                 (.clear candidates update-idx)
                 (recur (+ idx update-idx)))))
           (recur (inc idx)))))
    (p :final
       (take-while pos? (iterate #(.nextSetBit candidates (inc %)) 2)))))

(defn -main
  [& args]
  (->> (profiled {} (bitset-sieve 100000))
       second
       deref
       pprint))
```

Running this yields:

```plaintext
$ lein uberjar
Compiling t.core
Created target/uberjar/t-app.jar
Created target/uberjar/t-app-standalone.jar
$ java -jar target/uberjar/t-app-standalone.jar
{:stats
 {:init
  {:min 26889,
   :mean 26889.0,
   :p75 26889,
   :mad-sum 0.0,
   :p99 26889,
   :n 1,
   :p25 26889,
   :p90 26889,
   :max 26889,
   :mad 0.0,
   :p50 26889,
   :sum 26889,
   :p95 26889},
  :main-loop
  {:min 10101805,
   :mean 1.0101805E7,
   :p75 10101805,
   :mad-sum 0.0,
   :p99 10101805,
   :n 1,
   :p25 10101805,
   :p90 10101805,
   :max 10101805,
   :mad 0.0,
   :p50 10101805,
   :sum 10101805,
   :p95 10101805},
  :final
  {:min 528845,
   :mean 528845.0,
   :p75 528845,
   :mad-sum 0.0,
   :p99 528845,
   :n 1,
   :p25 528845,
   :p90 528845,
   :max 528845,
   :mad 0.0,
   :p50 528845,
   :sum 528845,
   :p95 528845}},
 :clock {:t0 65679371379713, :t1 65679382683192, :total 11303479}}
[22:42]gary@macbook-pro~/cuddly-octo-palm-tree/blog/minicode/2022-01-16
$
```

There's a lot that can be built out of those primitives (and a lot more tools
in the [tufte] toolbox); we'll cover a more interesting setup later on. For
now, the important points are:

- This gives us an easy way to get a good sense of where time is spent, at a
  fairly fine-grained level.
- The library is designed to be low-overhead, such that these performance logs
  can be left in the code and actually run in production. Obviously there is
  still _some_ overhead so you may not want to put a `p` call in the middle of
  your tightest loop, but it may be good enough to wrap the entire loop itself in
  a `p`.
- This can provide some insight after-the-fact, but you have to know in advance
  which sections of code you want to measure. In general, this will tell you
  which parts of your code are slow, but not necessarily why.

### Profiling

Profiling is generally done by running code under a _profiler_, which in our
case is a tool that attaches to a running JVM and adds all sorts of
instrumentation to the existing classes.

This means that the code you are profiling _is not_ the code that would run
under normal circumstances. Specifically, profiling makes code _a lot_ slower,
and may interfere with JIT optimizations.

On the other hand, profiling can give you a very detailed understanding of
exactly which operations your code is going through, and where time is spent.
Wheres performance logging could easily tell you which chunk of code is taking
up most of the time, a profiler will be able to tell you which underlying JVM
bytecode you spend most of your time running.

There's obviously a danger of getting too low-level there and getting a very
accurate, very complete picture that no human can make sense of. Personally, I
like stopping at the `clojure.**` classes, and see that as my "virtual machine".

My tool of choice for profiling is [VisualVM], mostly because it's free and I'm
used to it.

It's pretty easy to run, but you need a running process. If we wanted to
profile our `bitset-sieve` function from above, we would have to change the
`-main` function to wait for some signal. We'll go for a simple approach of
waiting for some input from the user:

```clojure
(defn -main
  [& args]
  (println "Waiting for profiler.")
  (read-line)
  (bitset-sieve 100000))
```




[aoc]: https://adventofcode.com
[tufte]: https://github.com/ptaoussanis/tufte
[timbre]: https://github.com/ptaoussanis/timbre
[primes]: /tags/primes
[VisualVM]: https://visualvm.github.io
