{:title "Monads, part two: Yes, but why?"
 :layout :post
 :tags ["monad-tutorial"]}

Even ignoring the implementation effort, if we look back at last week's code
and what it takes just to use a monad:

```java
        Fiber<Double> f2 =
            pure                (1) .bind(a ->
            debug("thread 2") .bind(    _1 ->
            pure                (2) .bind(b ->
            debug("thread 2") .bind(    _2 ->
            pure                (1) .bind(c ->
            debug("thread 2") .bind(    _3 ->
            pure            (b * b) .bind(b2 ->
            debug("thread 2") .bind(    _4 ->
            pure            (a * c) .bind(ac ->
            debug("thread 2") .bind(    _5 ->
            pure      (b2 - 4 * ac) .bind(delta ->
            debug("thread 2") .bind(    _6 ->
            pure (Math.sqrt(delta)) .bind(rac ->
            debug("thread 2") .bind(    _7 ->
            _return ((-b + rac) / (2 * a))
            ))))))))))))));
```

it's fair to wonder why anyone would ever want to do that.

Like most things in software engineering, or any engineering discipline for
that matter, the layman's answer is "it depends", while the professional answer
is a slightly more elaborate "you should use it when the benefits outweigh the
costs". As an engineering discipline, software engineering is fundamentally
unique in that, while we mostly follow the same cost/benefit analysis as other
engineering disciplines, we do away with the nasty, unnecessary and complicated
step of actually trying to objectively _measure_ costs and benefits, and we
just go with gut feeling instead, with the vague hope that through enough
experience we can shape our guts to eventually get good enough feelings.

In that spirit, let me try to lay down some guidelines about what to consider
when wondering whether you should use a monad. First, let's talk about costs.

### Costs

There are mainly three sources of costs for monadic abstractions, and all of
them vary wildly depending on which language you use (and by extension who you
work with):

1. Conceptual overhead,
2. Syntactic overhead, and
3. Implementation overhead.

The first hurdle is how much the set of people who are expected to review and
maintain the code you are about to write are themselves familiar with monads. I
would argue that monadic code is not fundamentally more complex than
non-monadic code, just like functional code is not fundamentally more complex
than imperative code, but it is definitely a different style and lack of
familiarity can get in the way of understanding.

Different monads can have different levels of complexity, and while you can
build additional abstractions on top of some monads (e.g. monad transformers),
if you and your team are not very familiar with them yet it may be best to just
start with a simple one, like `Maybe`,[^1] while everyone gets familiar with
that new way to structure code.

[^1]: Actually, don't ever use `Maybe`, use `Either` instead. It's pretty much
  the same, except the `none` constructor can carry a value.

The second hurdle is the syntactic overhead. This is extremely dependent on the
language you are using. In Java, as demonstrated, it's pretty bad. In Haskell,
while you could translate the above code directly to explicit `>>=` calls as
in:

```haskell
  pure 1 >>= (\a ->
  debug "thread 2" >>= (\_ ->
  pure 2 >>= (\b ->
  debug "thread 2" >>= (\_ ->
  pure 1 >>= (\c ->
  debug "thread 2" >>= (\_ ->
  pure (b * b) >>= (\b2 ->
  debug "thread 2" >>= (\_ ->
  pure (a * c) >>= (\ac ->
  debug "thread 2" >>= (\_ ->
  pure (b2 - 4 * ac) >>= (\delta ->
  debug "thread 2" >>= (\_ ->
  pure (delta ** 0.5) >>= (\rac ->
  debug "thread 2" >>= (\_ ->
  return ((rac - b) / (2 * a))
  ))))))))))))))
```

you can also use special syntax designed just for monads, whcih reads a lot
better:

```haskell
  do
    a <- pure 1
    debug "thread 2"
    b <- pure 2
    debug "thread 2"
    c <- pure 1
    debug "thread 2"
    b2 <- pure $ b * b
    debug "thread 2"
    ac <- pure $ a * c
    debug "thread 2"
    delta <- pure $ b2 - 4 * ac
    debug "thread 2"
    rac <- pure $ delta ** 0.5
    debug "thread 2"
    return $ (rac - b) / (2 * a)
```

in particular:

- There is no need to close all those parentheses at the end.
- Variable names precede their binding, just like normal assignment.
- Unused bindings can simply be omitted (as opposed to Java, which forced us to
  not only declare them but give them different names).

Scala similarly has special syntax in its `for` instruction that can be used to
implement monads in a fairly (syntactically) lightweight manner. Other
languages may have more or less syntactic noise and tools to manage it. Point
is, the cost here depends a lot on what language you're using.

The final source of cost for monads is the implementation, both in terms of the
effort to produce it and the runtime performance overhead. Monads are not
(generally) free, though this is by far the hardest one of the three costs to
speak of in a general sense.

Note that while I can give you some guidance about how to think about these
costs in the general sense, in each specific instance where you could opt to
use monad a proper cost evaluation would need to _compare_ the cost (and
benefits) of a monadic approach to the cost (and benefits) of the other
alternatives.

### Benefits


