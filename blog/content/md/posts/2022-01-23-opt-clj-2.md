{:title "Notes on Optimizing Clojure Code: Measurements"
 :layout :post
 :tags ["clojure"]}

Picking up from [last week], we'll delve into the three types of measurements I
talked about. Let's jump right in; if you need context, just read the [previous
post][last week].

### Performance logging

At its most basic, performance logging can just be timestamping your logs. (Or
wraping some parts of your code in `time` calls as we did above.) In many cases
that will be enough to give you a rough idea of which parts of your code are
slow, and that's really all we're after here.

The less linear your code is, the less effective that naive approach will be.
My tool of choice for performance logging is [tufte], which was extracted from
the [timbre] logging library. Compared to just adding timestamps to your
existing logs, its main advantage is that it will compute summarized times for
you.

At its most basic, the [tufte] library can be understood in terms of two
constructs:

- The `profiled` macro takes a single expression and returns a vector where the
  first element is the result of the given expression, and the second element
  is a summarized result of all the measurements taken.
- The `p` macro takes a keyword and an expression, and returns the result of
  that expression. It also, through side-effects, registers the time it took to
  compute that results under the given keyword.

We can instrument the code snippet above with [tufte] as follows:

```clojure
```

Running this yields:

```plaintext
$ lein uberjar
Compiling t.core
Created target/uberjar/t-app.jar
Created target/uberjar/t-app-standalone.jar
$ java -jar target/uberjar/t-app-standalone.jar
{:stats
 {:init
  {:min 26889,
   :mean 26889.0,
   :p75 26889,
   :mad-sum 0.0,
   :p99 26889,
   :n 1,
   :p25 26889,
   :p90 26889,
   :max 26889,
   :mad 0.0,
   :p50 26889,
   :sum 26889,
   :p95 26889},
  :main-loop
  {:min 10101805,
   :mean 1.0101805E7,
   :p75 10101805,
   :mad-sum 0.0,
   :p99 10101805,
   :n 1,
   :p25 10101805,
   :p90 10101805,
   :max 10101805,
   :mad 0.0,
   :p50 10101805,
   :sum 10101805,
   :p95 10101805},
  :final
  {:min 528845,
   :mean 528845.0,
   :p75 528845,
   :mad-sum 0.0,
   :p99 528845,
   :n 1,
   :p25 528845,
   :p90 528845,
   :max 528845,
   :mad 0.0,
   :p50 528845,
   :sum 528845,
   :p95 528845}},
 :clock {:t0 65679371379713, :t1 65679382683192, :total 11303479}}
[22:42]gary@macbook-pro~/cuddly-octo-palm-tree/blog/minicode/2022-01-16
$
```

There's a lot that can be built out of those primitives (and a lot more tools
in the [tufte] toolbox); we'll cover a more interesting setup later on. For
now, the important points are:

- This gives us an easy way to get a good sense of where time is spent, at a
  fairly fine-grained level.
- The library is designed to be low-overhead, such that these performance logs
  can be left in the code and actually run in production. Obviously there is
  still _some_ overhead so you may not want to put a `p` call in the middle of
  your tightest loop, but it may be good enough to wrap the entire loop itself in
  a `p`.
- This can provide some insight after-the-fact, but you have to know in advance
  which sections of code you want to measure. In general, this will tell you
  which parts of your code are slow, but not necessarily why.

### Profiling

Profiling is generally done by running code under a _profiler_, which in our
case is a tool that attaches to a running JVM and adds all sorts of
instrumentation to the existing classes.

This means that the code you are profiling _is not_ the code that would run
under normal circumstances. Specifically, profiling makes code _a lot_ slower,
and may interfere with JIT optimizations.

On the other hand, profiling can give you a very detailed understanding of
exactly which operations your code is going through, and where time is spent.
Wheres performance logging could easily tell you which chunk of code is taking
up most of the time, a profiler will be able to tell you which underlying JVM
bytecode you spend most of your time running.

There's obviously a danger of getting too low-level there and getting a very
accurate, very complete picture that no human can make sense of. Personally, I
like stopping at the `clojure.**` classes, and see that as my "virtual machine".

My tool of choice for profiling is [VisualVM], mostly because it's free and I'm
used to it.

It's pretty easy to run, but you need a running process. If we wanted to
profile our `bitset-sieve` function from above, we would have to change the
`-main` function to wait for some signal. We'll go for a simple approach of
waiting for some input from the user:

```clojure
(defn -main
  [& args]
  (println "Waiting for profiler.")
  (read-line)
  (bitset-sieve 100000))
```


[last week]: /posts/2022-01-16-opt-clj-1
[tufte]: https://github.com/ptaoussanis/tufte
[timbre]: https://github.com/ptaoussanis/timbre
[VisualVM]: https://visualvm.github.io
