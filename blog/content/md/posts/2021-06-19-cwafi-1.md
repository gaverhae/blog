{:title "Writing a simple interpreter"
 :layout :post
 :tags ["cwafi"]}

A few months ago, my former boss [Neil Mitchell][ndm] gave a talk entitled
"[Cheaply Writing a Fast Interpreter][cwafi]". It's a very good talk, and I'd
encourage you to watch it. The basic premise of the talk is that it is given to
people who already know many ways to write an interpreter, and the talk itself
is presenting the results of a study Neil did to compare a number of different
techniques in terms of the performance per cost ratio, where cost is meant in
terms of development and maintenance terms. The results presented should be of
great interest to anyone planning to write an interpreter for some practical
purpose.

I don't plan to write any real interpreter. What made the talk really
interesting to me is that I did not know any of the techniques Neil presented,
so the talk served as a great roadmap of things to go and play with.

## Parts of an interpreter

An interpreter is a program that takes in text that forms a valid program in
some programming language and executes it. Where the text comes from is not
terribly important. Starting with the point where we have some text, the major
parts of an interpreter are:

- The _parser_ is a function that takes in some "flat" text and produces some
  form of structured _tree_.
- The _optimizer_ takes in the tree produced by the parser, and transforms it
  into another tree. There may be any number of intermediate passes over any
  number of intermediate trees.
- The _evaluator_ reads in a tree emitted by the optimizer and actually does
  stuff as instructed by the input program.

Naming is not very consistent across sources I've come across. "Parsing" as a
transformation of text to tree is by far the most widely accepted term I've
found. Coming in second would be "abstract syntax tree", in that any piece
about interpreters will mention the words, though they're not always in
agreement on what they mean. As mentioned, there can be any number of different
trees in-between the textual representation and the one that eventually gets
evaluated, and which one of these trees is _the_ abstract syntax tree is fairly
inconsistent.

Finally, in some cases the evaluator can modify the tree it is evaluating. This
happens in broadly two cases:

- If the language being evaluated is _dynamic_, it will have operation to
  modify its own tree at runtime.
- The evaluator may modify the tree for optimization purposes. This can be
  called an optimizing evaluator, or a JIT (standing for "just-in-time
  compiler", because it's fun to make acronyms that miss some letters).

## Compilers

Mathematically, a compiler is any program that transforms programs written in
language \\(A\\) into equivalent programs written in language \\(B\\). There is
no restriction that \\(B\\) must be different from \\(A\\), or that \\(B\\)
must be a specific language.

Still, when hearing "compiler", many programmers will think of a program that
generates machine code. In a way, this is just a special case of an
interpreter, where the evaluator is the CPU and the interpreter lets us
serialize the result of the optimizer to disk rather than running it directly.

In a more general sense, compilers will look a lot like interpreters, in that
there will be a parser that produces some tree, and then a series of steps that
transform a series of trees. The evaluation part is replaced by the emission of
a "flat" file that represents code in the target language.

## Sample code

Our running example will be the same example used in [Neil's talk][cwafi]:

```c
x = 100;
for (i = 1000; i != 0; i--) {
  x = x + 4 + x + 3;
  x = x + 2 + 4;
}
x
```

I did some my explorations in Clojure, and some in Haskell, because these are
the two languages I wanted to play with. Most of what I'm going to write in
this series is non-language-specific, though.

This series is not about parsing, so we will start with a tree rather than raw
text. The specific shape of the tree will depend on the (interpreter) language,
but hopefully it should be close enough to the above snippet that the
correspondence is apparent.

Here is how I chose to represent the above program in a Haskell tree:

```haskell
newtype Name = Name String
  deriving (Eq, Ord, Show)
newtype Value = Value Int
  deriving (Eq, Show)
  deriving newtype Num

data Op
  = Add
  | Sub
  | Mul
  | NotEq
  deriving (Show)

data Exp where
  Lit :: Value -> Exp
  Var :: Name -> Exp
  Set :: Name -> Exp -> Exp
  Bin :: Op -> Exp -> Exp -> Exp
  Do :: [Exp] -> Exp
  While :: Exp -> Exp -> Exp
  Print :: Exp -> Exp
  deriving Show

bin :: Op -> Value -> Value -> Value
bin = \case
  Add -> (+)
  Sub -> (-)
  Mul -> (*)
  NotEq -> \v1 v2 -> if v1 /= v2 then 1 else 0

neil :: Exp
neil =
  let x = Name "x"
      i = Name "i"
      t = Name "t"
  in
  Do [
    Set x (Lit 100),
    Set i (Lit 1000),
    While (Bin NotEq (Lit 0) (Var i))
      (Do [
        Set x (Bin Add (Bin Add (Bin Add (Var x) (Lit 4)) (Var x)) (Lit 3)),
        Set x (Bin Add (Bin Add (Var x) (Lit 2)) (Lit 4)),
        Set i (Bin Add (Lit (-1)) (Var i))
      ]),
    Print $ Var x,
    Print $ Var t
    ]
```

And here is the same program in a Clojure tree:

```clojure
(def ast
  [:do
   [:set 0 [:lit 100]]
   [:set 1 [:lit 1000]]
   [:while [:not= [:lit 0] [:var 1]]
    [:do
     [:set 0 [:add [:add [:add [:var 0] [:lit 4]] [:var 0]] [:lit 3]]]
     [:set 0 [:add [:add [:var 0] [:lit 2]] [:lit 4]]]
     [:set 1 [:add [:lit -1] [:var 1]]]]]
   [:return [:var 0]]])
```



[ndm]: https://ndmitchell.com
[cwafi]: https://www.youtube.com/watch?v=V8dnIw3amLA
